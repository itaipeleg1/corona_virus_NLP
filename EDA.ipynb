{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03c8fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from models import data_preparation\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import RobertaForSequenceClassification, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, BertTokenizer\n",
    "from models.training_pytorch import objective, train_model_with_hyperparams\n",
    "from models.training_HF import objective_HF\n",
    "from models.model_config import model_configs\n",
    "import optuna\n",
    "import wandb\n",
    "import argparse\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9aea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = config.DATA_DIR \n",
    "TWEETS_DATA = pd.read_csv(data_path / \"Corona_NLP_train.csv\",encoding='ISO-8859-1') \n",
    "TEST_DATA = pd.read_csv(data_path / \"Corona_NLP_test.csv\",encoding='ISO-8859-1')\n",
    "CSV_PATH = config.DATA_DIR/\"processed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb9cb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27344c",
   "metadata": {},
   "source": [
    "# EDA \n",
    "We start exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500203d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "print(TWEETS_DATA.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8baf338",
   "metadata": {},
   "source": [
    "1. There are several id columns: Username and ScreenName\n",
    "2. The date, location of the tweet are categorical\n",
    "3. sentiment is categorical ordinal    \n",
    "    \n",
    "  **let's try to plot and understand the data better**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f68d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The number of unique ScreenNames: {np.unique(len(TWEETS_DATA['ScreenName']))}\")\n",
    "print(f\"The number of unique UserNames: {np.unique(len(TWEETS_DATA['UserName']))}\")\n",
    "print(\"The length of the data: \", len(TWEETS_DATA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08895f5a",
   "metadata": {},
   "source": [
    "First of all let's plot the Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4330b362",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_order = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(data=TWEETS_DATA, x='Sentiment', order=custom_order, palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TWEETS_DATA[\"TweetAt\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb414ec",
   "metadata": {},
   "source": [
    "We Can see that the data was taken in march and april,  when covid was at its initial peak, \n",
    "let's see if the month can tell us something.  \n",
    "Maybe one month was more negative than the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1527c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_DATA[\"month\"] = pd.to_datetime(TWEETS_DATA[\"TweetAt\"]).dt.month\n",
    "print(TWEETS_DATA[\"month\"].value_counts())\n",
    "## plot sentiment by month\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=TWEETS_DATA, x='month', hue='Sentiment', hue_order=custom_order)\n",
    "plt.title('Sentiment Distribution by Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ef4dd",
   "metadata": {},
   "source": [
    "It looks like it distributes the same, counting that march had twice has much tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2dfd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TWEETS_DATA[\"Location\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e1f02",
   "metadata": {},
   "source": [
    "It seems that are too many different locations to try to put them together, we will look into it later $$$**##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12f837b",
   "metadata": {},
   "source": [
    "**Now let's plot the tweets data, let's see what's poping as obvious**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63329f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_DATA['text_len'] = TWEETS_DATA['OriginalTweet'].str.len()\n",
    "sns.histplot(TWEETS_DATA['text_len'], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9679b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Compute number of tokens per tweet\n",
    "TWEETS_DATA['num_bert_tokens'] = TWEETS_DATA['OriginalTweet'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "\n",
    "# Plot histogram\n",
    "sns.histplot(TWEETS_DATA['num_bert_tokens'], bins=30)\n",
    "plt.xlabel(\"Number of BERT Tokens per Tweet\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of BERT Token Counts in Tweets\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914f4d0",
   "metadata": {},
   "source": [
    "We know the tweeter (former X) had a 280 charecters limit, over it are paid users.  \n",
    "let's see if it can gain us some knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ee134",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_DATA[\"paid_user\"] = TWEETS_DATA[\"OriginalTweet\"].apply(lambda x: \"paid\" if len(x) > 280 else \"free\")\n",
    "sns.countplot(data=TWEETS_DATA, x='paid_user', hue='Sentiment', hue_order=custom_order)\n",
    "plt.xlabel(\"Is_user paying?\")\n",
    "paid_users = TWEETS_DATA[TWEETS_DATA['paid_user'] == 'paid']\n",
    "free_users = TWEETS_DATA[TWEETS_DATA['paid_user'] == 'free']\n",
    "\n",
    "positive = paid_users[paid_users['Sentiment'].isin(['Positive','Extremley Positive'])]['OriginalTweet'].tolist()\n",
    "negative = paid_users[paid_users['Sentiment'].isin(['Negative','Extremley Negative'])]['OriginalTweet'].tolist()\n",
    "print(f\"Ratio of positive to negative tweets in paid users: {len(positive) / len(negative)}\")\n",
    "\n",
    "positive = free_users[free_users['Sentiment'].isin(['Positive','Extremley Positive'])]['OriginalTweet'].tolist()\n",
    "negative = free_users[free_users['Sentiment'].isin(['Negative','Extremley Negative'])]['OriginalTweet'].tolist()\n",
    "print(f\"The ratio of positive to negative tweets in free users: {len(positive) / len(negative)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d9e05",
   "metadata": {},
   "source": [
    "The ratios of negative vs positive are relatively the same for paid and free users, so status isn't a good indicator of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199058b",
   "metadata": {},
   "source": [
    "## Wordclouds\n",
    "Wordclouds are a great way to visualize the most common words in the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2acbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(TWEETS_DATA['OriginalTweet'])\n",
    "WordCloud(width=800, height=400).generate(text).to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2633713e",
   "metadata": {},
   "source": [
    "https, amp, t, u, Â, itÂ, donÂ, IÂ  Are HTML tokens that we need to take out of the dataset! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSTEAD OF THIS i SUGGEST DOING THIS (because currently some symbols like \\r\\r\\n\\r\\r\\n are still present):\n",
    "\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\bamp\\b', '', text)                 # Remove \"amp\"\n",
    "    text = re.sub(r'\\r|\\n', ' ', text)                  # Replace \\r and \\n with space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()                    # Remove mentions\n",
    "    return text\n",
    "\n",
    "#apply:\n",
    "TWEETS_DATA[\"tweets\"] = TWEETS_DATA[\"OriginalTweet\"].apply(clean_tweet)\n",
    "TEST_DATA[\"tweets\"] = TEST_DATA[\"OriginalTweet\"].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(TWEETS_DATA['tweets'])\n",
    "WordCloud(width=800, height=400).generate(text).to_image()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "53ddb88b",
   "metadata": {},
   "source": [
    "In order to take care of weird signs like: ![image.png](attachment:image.png)  \n",
    "We tried different encodings (latin and ISO-8859-1)  \n",
    "We going to take it out manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_DATA[\"tweets\"] = TWEETS_DATA[\"tweets\"].apply(\n",
    "    lambda x: x.encode('ascii', errors='ignore').decode()\n",
    ")\n",
    "\n",
    "TEST_DATA[\"tweets\"] = TEST_DATA[\"tweets\"].apply(\n",
    "    lambda x: x.encode('ascii', errors='ignore').decode()\n",
    ")\n",
    "text = \" \".join(TWEETS_DATA['tweets'])\n",
    "WordCloud(width=800, height=400).generate(text).to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500d5bc",
   "metadata": {},
   "source": [
    "Now we will explore more wordclouds - per sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85fe5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = custom_order\n",
    "num_clouds = len(sentiments)\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(5, 20))\n",
    "\n",
    "\n",
    "# If only one sentiment, axes isn't a list — make it one\n",
    "if num_clouds == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each sentiment and create a word cloud\n",
    "for ax, sentiment in zip(axes, sentiments):\n",
    "    subset = TWEETS_DATA[TWEETS_DATA['Sentiment'] == sentiment]\n",
    "    text = \" \".join(subset['tweets'])\n",
    "    \n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    \n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.set_title(sentiment)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24033c9e",
   "metadata": {},
   "source": [
    "Looks like all wordclouds contain similar words, perhaps dipper analysis should be done while extracting covid related key words, to explore better sentiment related words (becuase obsviously positive and negative tweets discussed covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85faba3",
   "metadata": {},
   "source": [
    "**As we all know X (former tweeter) has # and @ in the tweets, let's try to gain some insight from it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d218fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract @ and #\n",
    "TWEETS_DATA['hashtags'] = TWEETS_DATA['OriginalTweet'].str.findall(r'#\\w+')\n",
    "TWEETS_DATA['ats'] = TWEETS_DATA['OriginalTweet'].str.findall(r'@\\w+')\n",
    "\n",
    "# Explode and clean\n",
    "hashtags_df = TWEETS_DATA.explode('hashtags')\n",
    "ats_df = TWEETS_DATA.explode('ats')\n",
    "\n",
    "hashtags_df = hashtags_df[hashtags_df['hashtags'].notna()]\n",
    "ats_df = ats_df[ats_df['ats'].notna()]\n",
    "\n",
    "# Top N\n",
    "top_n = 15\n",
    "top_hashtags = hashtags_df['hashtags'].value_counts().nlargest(top_n).index\n",
    "top_ats = ats_df['ats'].value_counts().nlargest(top_n).index\n",
    "\n",
    "# Filtered\n",
    "filtered_hashtags = hashtags_df[hashtags_df['hashtags'].isin(top_hashtags)]\n",
    "filtered_ats = ats_df[ats_df['ats'].isin(top_ats)]\n",
    "\n",
    "# Plot side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6), sharey=False)\n",
    "\n",
    "sns.countplot(data=filtered_hashtags, x='hashtags', order=top_hashtags, palette='viridis', ax=axes[0])\n",
    "axes[0].set_title(f\"Top {top_n} Hashtags\")\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.countplot(data=filtered_ats, x='ats', order=top_ats, palette='coolwarm', ax=axes[1])\n",
    "axes[1].set_title(f\"Top {top_n} Mentions\")\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter again to include Sentiment\n",
    "sentiment_hashtags_df = hashtags_df[hashtags_df['hashtags'].isin(top_hashtags)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=sentiment_hashtags_df, x='hashtags', hue='Sentiment', order=top_hashtags, hue_order=custom_order)\n",
    "plt.title('Sentiment Distribution for Top 15 Hashtags')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd562e56",
   "metadata": {},
   "source": [
    "We can see that hashtags are pretty balanced across sentiments, and also that many are variations on same words, like covid, covid19, coronavirus, corona, etc. So hashtags for now don't seem useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1357a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter again to include Sentiment\n",
    "sentiment_ats_df = ats_df[ats_df['ats'].isin(top_ats)]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=sentiment_ats_df, x='ats', hue='Sentiment', order=top_ats, hue_order=custom_order)\n",
    "plt.title('Sentiment Distribution for Top 15 ats')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7415c1d",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "After the exploring and some preprocessing we already made (removing special characters, html...), we shall prepare our data to the models of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make labels numerical using a dict:\n",
    "label_map = {\n",
    "    \"Extremely Negative\": 0,\n",
    "    \"Negative\": 1,\n",
    "    \"Neutral\": 2,\n",
    "    \"Positive\": 3,\n",
    "    \"Extremely Positive\": 4\n",
    "}\n",
    "# Convert labels to numerical values\n",
    "TWEETS_DATA['Sentiment'] = TWEETS_DATA['Sentiment'].map(label_map)\n",
    "TEST_DATA['Sentiment'] = TEST_DATA['Sentiment'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bacd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_DATA\n",
    "#I can see that there are still some symbols like: \\r\\r\\n\\r\\r\\n - we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9327917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for models: leave only text and labels\n",
    "train_df = TWEETS_DATA[['tweets', 'Sentiment']]\n",
    "test_df = TEST_DATA[['tweets', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e382a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save (earlier )\n",
    "train_df.to_csv(CSV_PATH / 'train_data.csv', index=False)\n",
    "test_df.to_csv(CSV_PATH / 'test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d6916",
   "metadata": {},
   "source": [
    "## Part B: Further analysis for second training of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62eaf3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_confusion_matrix(model, val_loader, device, class_names=None, normalize=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype(\"float\") / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Display\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix - Val Set\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Classification report\n",
    "    if class_names:\n",
    "        print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "    else:\n",
    "\n",
    "        print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e7d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_model_with_hyperparams() missing 1 required positional argument: 'fold'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m criterion = torch.nn.CrossEntropyLoss()\n\u001b[32m     30\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m best_val_acc = \u001b[43mtrain_model_with_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfor_confusion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: train_model_with_hyperparams() missing 1 required positional argument: 'fold'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_key = \"bertweet\"\n",
    "config = model_configs[model_key]\n",
    "tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "model_name = config[\"model_name\"]\n",
    "model_class = config[\"model_class\"]\n",
    "max_length = config[\"max_length\"]\n",
    "tokenizer_class = config[\"tokenizer_class\"]\n",
    "base_attr = config[\"base_attr\"]\n",
    "project_name=\"for_confusion\"\n",
    "lr = 0.000027603\n",
    "weight_decay = 0.000057487\n",
    "patience = 10 \n",
    "batch_size = 64\n",
    "num_layers = 2\n",
    "\n",
    "train_dataset,val_dataset, test_dataset = data_preparation.prepare_dataset(tokenizer,max_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "model = model_class.from_pretrained(model_name, num_labels=5)\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.roberta.encoder.layer[-num_layers:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "best_val_acc = train_model_with_hyperparams(model, train_loader, val_loader,optimizer, criterion, epochs=20, patience=patience,trial=1,device=device, project_name=\"for_confusion\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be9aa60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m## Load model from file\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#  \"bertweet\": {\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#         \"model_name\": \"vinai/bertweet-base\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#         \"max_length\": 128  ##critical for covidbert\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m#     },\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m model = \u001b[43mBertForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdigitalepidemiologylab/covid-twitter-bert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m model_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresults/run_2.4_covidbert_HF/best_model_trial_1_fold_0.pt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m model.load_state_dict(torch.load(model_path))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4333\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   4328\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   4329\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4330\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4331\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4332\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1369\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1366\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1367\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:928\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    932\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    933\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    938\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    939\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:955\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    951\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    952\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    953\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    956\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    958\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_subclasses\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfake_tensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FakeTensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1348\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1349\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1350\u001b[39m             device,\n\u001b[32m   1351\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1352\u001b[39m             non_blocking,\n\u001b[32m   1353\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1354\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1356\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1357\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1358\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "## Load model from file\n",
    "#  \"bertweet\": {\n",
    "#         \"model_name\": \"vinai/bertweet-base\",\n",
    "#         \"model_class\": RobertaForSequenceClassification,\n",
    "#         \"tokenizer_class\": BertweetTokenizer,\n",
    "#         \"base_attr\": \"roberta\",\n",
    "#         \"max_length\": 128  # critical for bertweet\n",
    "#     },\n",
    "#     \"covidbert\": {\n",
    "#         \"model_name\": \"digitalepidemiologylab/covid-twitter-bert\",\n",
    "#         \"model_class\": BertForSequenceClassification,\n",
    "#         \"tokenizer_class\": BertTokenizer,\n",
    "#         \"base_attr\": \"bert\",\n",
    "#         \"max_length\": 128  ##critical for covidbert\n",
    "#     },\n",
    "model = BertForSequenceClassification.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\", num_labels=5).to(device)\n",
    "model_path = f\"results/run_2.4_covidbert_HF/best_model_trial_1_fold_0.pt\"\n",
    "model.load_state_dict(torch.load(model_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae99868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [160,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [161,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [162,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [163,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [164,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [165,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [166,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [167,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [168,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [169,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [170,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [171,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [172,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [173,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [174,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [175,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [176,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [177,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [178,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [179,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [180,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [181,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [182,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [183,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [184,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [185,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [186,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [187,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [188,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [189,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [190,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [1806,0,0], thread: [191,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate_model_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExtNeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNeg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNeutral\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPos\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExtPos\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mevaluate_model_confusion_matrix\u001b[39m\u001b[34m(model, val_loader, device, class_names, normalize)\u001b[39m\n\u001b[32m      9\u001b[39m attention_mask = batch[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m     10\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m preds = torch.argmax(outputs.logits, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     15\u001b[39m all_preds.extend(preds.cpu().numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1488\u001b[39m, in \u001b[36mBertForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1480\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1481\u001b[39m \u001b[33;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[32m   1482\u001b[39m \u001b[33;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[32m   1483\u001b[39m \u001b[33;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[32m   1484\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1485\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1486\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1488\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1489\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1500\u001b[39m pooled_output = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m   1502\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.dropout(pooled_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:942\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    939\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    940\u001b[39m         token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m embedding_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    951\u001b[39m     attention_mask = torch.ones((batch_size, seq_length + past_key_values_length), device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:181\u001b[39m, in \u001b[36mBertEmbeddings.forward\u001b[39m\u001b[34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    180\u001b[39m     inputs_embeds = \u001b[38;5;28mself\u001b[39m.word_embeddings(input_ids)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m token_type_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken_type_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m embeddings = inputs_embeds + token_type_embeddings\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.position_embedding_type == \u001b[33m\"\u001b[39m\u001b[33mabsolute\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/modules/sparse.py:192\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/hdd/anatkorol/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2546\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2540\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2541\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2542\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2543\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2544\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2545\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2546\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_confusion_matrix(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    class_names=[\"ExtNeg\", \"Neg\", \"Neutral\", \"Pos\", \"ExtPos\"],\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc1190",
   "metadata": {},
   "source": [
    "#### From the Confusion matrix we can see that the model tens to miss Extremly positive and Extremly Negatives.  \n",
    "Let's take a look at them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c910b0",
   "metadata": {},
   "source": [
    "EXTREMLY NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TWEETS_DATA[TWEETS_DATA['Sentiment'] == 0]['tweets'].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27548ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TWEETS_DATA[TWEETS_DATA['Sentiment'] == 1]['tweets'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TWEETS_DATA[TWEETS_DATA['Sentiment'] == 4]['tweets'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TWEETS_DATA[TWEETS_DATA['Sentiment'] == 3]['tweets'].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
